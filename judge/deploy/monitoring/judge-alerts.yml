groups:
  - name: judge
    rules:
      - alert: JudgeApiDown
        expr: up{job="judge-api"} == 0
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: "Judge API target is down"
          description: "Prometheus cannot scrape judge-api for at least 2 minutes."

      - alert: JudgeLightWorkersMissing
        expr: (sum(node_systemd_unit_state{job="node-exporter",name=~"judge-worker-light@[0-9]+\\.service",state="active"}) or vector(0)) < __LIGHT_WORKERS__
        for: __WORKER_HEALTH_FOR__
        labels:
          severity: critical
        annotations:
          summary: "Judge light workers missing active units"
          description: "Active light worker units stayed below __LIGHT_WORKERS__ for __WORKER_HEALTH_FOR__."

      - alert: JudgeTorchWorkersMissing
        expr: (sum(node_systemd_unit_state{job="node-exporter",name=~"judge-worker-torch@[0-9]+\\.service",state="active"}) or vector(0)) < __TORCH_WORKERS__
        for: __WORKER_HEALTH_FOR__
        labels:
          severity: critical
        annotations:
          summary: "Judge torch workers missing active units"
          description: "Active torch worker units stayed below __TORCH_WORKERS__ for __WORKER_HEALTH_FOR__."

      - alert: JudgeLightQueueBacklogHigh
        expr: judge_queue_group_lag{stream="queue:light",group="workers-light"} > __LIGHT_BACKLOG_WARN__
        for: __BACKLOG_WARN_FOR__
        labels:
          severity: warning
        annotations:
          summary: "Judge light queue backlog is high"
          description: "Light queue lag stayed above __LIGHT_BACKLOG_WARN__ jobs for __BACKLOG_WARN_FOR__."

      - alert: JudgeTorchQueueBacklogHigh
        expr: judge_queue_group_lag{stream="queue:torch",group="workers-torch"} > __TORCH_BACKLOG_WARN__
        for: __BACKLOG_WARN_FOR__
        labels:
          severity: warning
        annotations:
          summary: "Judge torch queue backlog is high"
          description: "Torch queue lag stayed above __TORCH_BACKLOG_WARN__ jobs for __BACKLOG_WARN_FOR__."

      - alert: JudgeQueueWaitP95High
        expr: |
          histogram_quantile(0.95, sum by (profile, le) (rate(judge_job_queue_wait_seconds_bucket[__QUEUE_WAIT_WINDOW__]))) > __QUEUE_WAIT_P95_WARN_SECONDS__
          and
          sum by (profile) (increase(judge_job_started_total[__QUEUE_WAIT_WINDOW__])) >= __QUEUE_WAIT_MIN_STARTS__
        for: __QUEUE_WAIT_FOR__
        labels:
          severity: warning
        annotations:
          summary: "Judge queue wait p95 is high"
          description: "Queue wait p95 stayed above __QUEUE_WAIT_P95_WARN_SECONDS__s for __QUEUE_WAIT_FOR__ with at least __QUEUE_WAIT_MIN_STARTS__ started jobs in __QUEUE_WAIT_WINDOW__."

      - alert: JudgeInternalErrorRateHigh
        expr: |
          (
            sum by (profile) (rate(judge_job_finished_total{status="error",error_kind="internal"}[__INTERNAL_ERROR_WINDOW__]))
            /
            clamp_min(sum by (profile) (rate(judge_job_finished_total[__INTERNAL_ERROR_WINDOW__])), 1)
          ) > __INTERNAL_ERROR_RATE_THRESHOLD__
          and
          sum by (profile) (increase(judge_job_finished_total[__INTERNAL_ERROR_WINDOW__])) >= __INTERNAL_ERROR_MIN_COMPLETIONS__
        for: __INTERNAL_ERROR_FOR__
        labels:
          severity: warning
        annotations:
          summary: "Judge internal error ratio is high"
          description: "Internal error ratio stayed above __INTERNAL_ERROR_RATE_THRESHOLD__ over __INTERNAL_ERROR_WINDOW__ with at least __INTERNAL_ERROR_MIN_COMPLETIONS__ completions for the affected profile."
