{
  "id": "build-gpt/05-attention-mechanism/02-causal-attention",
  "version": "v1",
  "runner": "causal_attention(Q, K, V)",
  "requires_torch": true,
  "time_limit_s": 5,
  "memory_mb": 1024,
  "comparison": {
    "type": "allclose",
    "rtol": 1e-05,
    "atol": 1e-08
  }
}
