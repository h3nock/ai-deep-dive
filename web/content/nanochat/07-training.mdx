---
title: The Training Loop
step: 7
description: Implementing the optimization loop, loss calculation, and backprop.
---

<SplitLayout>
  <Step>
    <Description>
      ## Learning

      We will write a robust training loop to optimize our model on the FineWeb-EDU dataset.

      ### What we'll build
      - The training loop with `AdamW`.
      - Learning rate scheduling.
      - Checkpointing.
      
      > [!NOTE]
      > This content is under construction.
    </Description>
  </Step>
</SplitLayout>
