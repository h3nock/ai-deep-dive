---
title: "Positional Encoding"
step: 4
description: "Why giving AI a sense of order requires re-inventing how we count."
---

<div className="flex flex-col" style={{ gap: 'var(--space-flow)' }}>
<Description noMargin>
  In the previous chapter, we solved the meaning problem. Each token now has an embedding vector that captures *what* it means. But we left one question unanswered: how does the model know *where* each word appears?
</Description>

<Description>
  Recall that Transformers process all words **in parallel** rather than one-by-one. This is what makes them fast. But it also means the model receives all embeddings at once, with no inherent notion of "first" or "last."
</Description>

<Description>
  Consider two sentences: **"Alice gave Bob a book"** and **"Bob gave Alice a book"**. They contain the exact same words. If we look up their embeddings, both sentences produce the same set of vectors. The only difference is the order.
</Description>

<div className="my-6 grid grid-cols-1 md:grid-cols-2 gap-4">
  <div className="p-4 bg-surface rounded-lg border border-border">
    <div className="text-xs font-semibold text-muted uppercase tracking-wider mb-2">Sentence A</div>
    <div className="text-primary font-medium mb-3">"Alice gave Bob a book"</div>
    <div className="font-mono text-xs text-secondary">
      [<span className="text-emerald-400">E(Alice)</span>, E(gave), <span className="text-sky-400">E(Bob)</span>, ...]
    </div>
  </div>
  <div className="p-4 bg-surface rounded-lg border border-border">
    <div className="text-xs font-semibold text-muted uppercase tracking-wider mb-2">Sentence B</div>
    <div className="text-primary font-medium mb-3">"Bob gave Alice a book"</div>
    <div className="font-mono text-xs text-secondary">
      [<span className="text-sky-400">E(Bob)</span>, E(gave), <span className="text-emerald-400">E(Alice)</span>, ...]
    </div>
  </div>
</div>

<Description>
  The Transformer's core mechanism, **Self-Attention**, determines how words relate by computing a dot product between their vectors. This dot product produces a **single number** (a score) representing how strongly two words are connected. The problem? E(Alice) Â· E(Bob) returns the exact same score regardless of which sentence they came from.
</Description>

<Description>
  The model sees "Alice" and "Bob" are related. It cannot tell which one is the Subject (giver) and which is the Object (receiver). Order matters for meaning, but there is nothing in these vectors that encodes order. We need to inject position information.
</Description>
</div>



<Step title="1. Attempt 1: Counting Up">
  <Description>
    The most obvious idea: number the positions 1, 2, 3... and add this integer to each embedding dimension.
  </Description>

  <Description attached>
    Let's see what happens at position 1000:
  </Description>

  <div className="content-attached">
    <div className="p-4 bg-[#121212] rounded-lg border border-zinc-800 font-mono text-sm">
      <div className="flex items-center gap-4">
        <span className="text-muted w-28 shrink-0">E("Apple")</span>
        <span className="text-primary">[0.05, -0.02, 0.11]</span>
      </div>
      <div className="flex items-center gap-4 mt-1">
        <span className="text-muted w-28 shrink-0">+ Position 1000</span>
        <span className="text-secondary">[1000, 1000, 1000]</span>
      </div>
      <div className="border-t border-zinc-700 mt-2 pt-2 flex items-center gap-4">
        <span className="text-muted w-28 shrink-0">= Result</span>
        <span className="text-amber-400 font-bold">[1000.05, 999.98, 1000.11]</span>
      </div>
    </div>
  </div>

  <Description>
    Look at the result. The values that encoded "Apple" (0.05, -0.02, 0.11) are now invisible. Whether the original word was "Apple", "Banana", or "King", the output is essentially [1000, 1000, 1000]. The meaning of the word is **drowned** by the position.
  </Description>

  <Description>
    There is a second problem. Recall from Chapter 3 that neural networks learn by finding the right **weights** to multiply inputs. But a single weight cannot work well for both small and large numbers. A weight tuned to work for position 1 will produce wildly different results for position 1000. The model has no way to learn a consistent relationship between position 1 and position 1000 because they live at completely different scales.
  </Description>

  <Description>
    Both problems stem from the same root cause: **unbounded values**. As sequences get longer, the position numbers grow without limit.
  </Description>
</Step>
