{
  "steps": [
    { "slug": "01-from-text-to-bytes", "step": 1 },
    { "slug": "02-tokenization", "step": 2 },
    { "slug": "03-embeddings", "step": 3 },
    { "slug": "04-attention-mechanism", "step": 4 },
    { "slug": "05-implementing-attention", "step": 5 },
    { "slug": "06-layer-norm-and-feed-forward", "step": 6 },
    { "slug": "07-residual-connections", "step": 7 },
    { "slug": "08-cross-attention", "step": 8 },
    { "slug": "09-project-translator", "step": 9 },
    { "slug": "p1-01-setup", "step": 9.1 },
    { "slug": "p1-02-assembly", "step": 9.2 },
    { "slug": "p1-03-training", "step": 9.3 },
    { "slug": "10-decoder-only-shift", "step": 10 },
    { "slug": "p2-01-setup", "step": 10.1 },
    { "slug": "p2-02-assembly", "step": 10.2 },
    { "slug": "p2-03-training", "step": 10.3 },
    { "slug": "p2-04-inference", "step": 10.4 },
    { "slug": "11-project-gpt", "step": 11 }
  ]
}
