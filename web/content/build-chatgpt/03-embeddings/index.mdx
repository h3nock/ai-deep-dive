---
title: "The Vector Space"
step: 3
description: "How to represent tokens as vectors to capture semantic meaning and sequence order."
---

<div className="flex flex-col gap-4">
<Description>
  In the previous chapter, we built a Tokenizer. We can now take a sentence like "I love cats" and convert it into a list of integers, something like `[40, 1842, 9246]`. It feels like we are ready. Computers operate on numbers, so why can we not just feed these integers directly into the Neural Network?
</Description>

<Description>
  To answer this, you have to understand how a Neural Network actually "thinks." It is a mathematical engine. It uses multiplication, addition, dot products, and gradients (calculus) to find patterns. Crucially, it assumes that **Magnitude Matters**.
</Description>
</div>


<Step title="1. The Problem with Raw Token IDs">
  <Description>
    Suppose we fed raw Token IDs directly into the model. Imagine the tokenizer assigned IDs like this:
  </Description>

  <div className="my-4 p-4 bg-slate-50 dark:bg-slate-800/50 rounded-lg border border-slate-200 dark:border-slate-700">
    <div className="space-y-2 font-mono text-sm">
      <div className="flex items-center gap-4">
        <span className="text-slate-500 dark:text-slate-400 w-20">ID 100:</span>
        <span className="text-slate-800 dark:text-slate-200 font-semibold">"Apple"</span>
      </div>
      <div className="flex items-center gap-4">
        <span className="text-slate-500 dark:text-slate-400 w-20">ID 500:</span>
        <span className="text-slate-800 dark:text-slate-200 font-semibold">"Banana"</span>
      </div>
    </div>
  </div>

  <Description>
    If you feed the number 100 and the number 500 into a neuron, the math implicitly assumes that the second input is "5 times greater" than the first.
  </Description>

  <Description>
    This relationship is purely arithmetic. It has nothing to do with the relationship between an Apple and a Banana. These numbers are distinct labels, similar to Employee IDs in a company database. Employee #500 is not "5 times better" than Employee #100; they are just different people.
  </Description>

  <div className="my-4 p-4 bg-slate-100 dark:bg-slate-800/60 rounded-lg border border-slate-200 dark:border-slate-700">
    <div className="text-sm font-medium text-slate-700 dark:text-slate-300 mb-2">The Core Problem</div>
    <div className="text-sm text-slate-600 dark:text-slate-400">
      If we force the model to do math on these arbitrary IDs, we are asking it to find patterns in chaos. The gradients will explode because the <strong>numerical relationships</strong> (100 vs 500) contradict the <strong>semantic relationships</strong> (Fruit vs Fruit).
    </div>
  </div>

  <Description>
    We need a way to represent words where the numbers themselves actually contain the meaning.
  </Description>
</Step>


<Step title="2. Representing Meaning with Multiple Numbers">
  <Description>
    If a single number (an integer) fails to capture meaning, what if we used multiple numbers?
  </Description>

  <Description>
    Consider a system where the numbers represent qualities of the object. To keep this intuitive, we will stick to two dimensions: **Royalty** and **Gender**.
  </Description>

  <Description>
    Each axis is a question scored from **-1.0** to **+1.0**:
    <ul>
      <li><strong>Royalty:</strong> "Is this about royalty?" (+1 strongly yes, -1 strongly the opposite, 0 unrelated)</li>
      <li><strong>Gender:</strong> "Is this masculine or feminine?" (+1 masculine, -1 feminine, 0 neutral)</li>
    </ul>
  </Description>

  <div className="my-6 grid grid-cols-1 md:grid-cols-2 gap-4">
    <div className="p-4 bg-slate-50 dark:bg-slate-800/50 rounded-lg border border-slate-200 dark:border-slate-700">
      <div className="flex items-center gap-3 mb-3">
        <span className="text-2xl">üëë</span>
        <span className="font-bold text-lg text-slate-800 dark:text-slate-200">King</span>
      </div>
      <div className="space-y-2 text-sm">
        <div className="flex justify-between">
          <span className="text-slate-500 dark:text-slate-400">Royalty:</span>
          <span className="font-mono font-semibold text-emerald-600 dark:text-emerald-400">1.0</span>
        </div>
        <div className="flex justify-between">
          <span className="text-slate-500 dark:text-slate-400">Gender:</span>
          <span className="font-mono font-semibold text-blue-600 dark:text-blue-400">1.0</span>
        </div>
        <div className="pt-2 border-t border-slate-200 dark:border-slate-700 flex justify-between">
          <span className="text-slate-500 dark:text-slate-400">Vector:</span>
          <span className="font-mono font-bold text-slate-800 dark:text-slate-200">[1.0, 1.0]</span>
        </div>
      </div>
    </div>

    <div className="p-4 bg-slate-50 dark:bg-slate-800/50 rounded-lg border border-slate-200 dark:border-slate-700">
      <div className="flex items-center gap-3 mb-3">
        <span className="text-2xl">üë∏</span>
        <span className="font-bold text-lg text-slate-800 dark:text-slate-200">Queen</span>
      </div>
      <div className="space-y-2 text-sm">
        <div className="flex justify-between">
          <span className="text-slate-500 dark:text-slate-400">Royalty:</span>
          <span className="font-mono font-semibold text-emerald-600 dark:text-emerald-400">1.0</span>
        </div>
        <div className="flex justify-between">
          <span className="text-slate-500 dark:text-slate-400">Gender:</span>
          <span className="font-mono font-semibold text-pink-600 dark:text-pink-400">-1.0</span>
        </div>
        <div className="pt-2 border-t border-slate-200 dark:border-slate-700 flex justify-between">
          <span className="text-slate-500 dark:text-slate-400">Vector:</span>
          <span className="font-mono font-bold text-slate-800 dark:text-slate-200">[1.0, -1.0]</span>
        </div>
      </div>
    </div>

    <div className="p-4 bg-slate-50 dark:bg-slate-800/50 rounded-lg border border-slate-200 dark:border-slate-700">
      <div className="flex items-center gap-3 mb-3">
        <span className="text-2xl">üßî</span>
        <span className="font-bold text-lg text-slate-800 dark:text-slate-200">Man</span>
      </div>
      <div className="space-y-2 text-sm">
        <div className="flex justify-between">
          <span className="text-slate-500 dark:text-slate-400">Royalty:</span>
          <span className="font-mono font-semibold text-slate-500 dark:text-slate-400">0.0</span>
        </div>
        <div className="flex justify-between">
          <span className="text-slate-500 dark:text-slate-400">Gender:</span>
          <span className="font-mono font-semibold text-blue-600 dark:text-blue-400">1.0</span>
        </div>
        <div className="pt-2 border-t border-slate-200 dark:border-slate-700 flex justify-between">
          <span className="text-slate-500 dark:text-slate-400">Vector:</span>
          <span className="font-mono font-bold text-slate-800 dark:text-slate-200">[0.0, 1.0]</span>
        </div>
      </div>
    </div>

    <div className="p-4 bg-slate-50 dark:bg-slate-800/50 rounded-lg border border-slate-200 dark:border-slate-700">
      <div className="flex items-center gap-3 mb-3">
        <span className="text-2xl">üçé</span>
        <span className="font-bold text-lg text-slate-800 dark:text-slate-200">Apple</span>
      </div>
      <div className="space-y-2 text-sm">
        <div className="flex justify-between">
          <span className="text-slate-500 dark:text-slate-400">Royalty:</span>
          <span className="font-mono font-semibold text-slate-500 dark:text-slate-400">0.0</span>
        </div>
        <div className="flex justify-between">
          <span className="text-slate-500 dark:text-slate-400">Gender:</span>
          <span className="font-mono font-semibold text-slate-500 dark:text-slate-400">0.0</span>
        </div>
        <div className="pt-2 border-t border-slate-200 dark:border-slate-700 flex justify-between">
          <span className="text-slate-500 dark:text-slate-400">Vector:</span>
          <span className="font-mono font-bold text-slate-800 dark:text-slate-200">[0.0, 0.0]</span>
        </div>
      </div>
    </div>
  </div>

  <Description>
    This is the breakthrough. By representing each word as a list of attributes (a **Vector**), we have encoded meaning into the numbers themselves. Look at the cards above: King and Queen share the same Royalty score, King and Man share the same Gender score, and Apple sits at zero for both because these human qualities simply do not apply to fruit.
  </Description>
</Step>


<Step title="3. Visualizing the Meaning Space">
  <Description>
    In the example above, we acted as human linguists and picked the categories. In real LLMs, we give the model 4096 dimensions and let it figure out what they mean.
  </Description>

  <Description>
    But because we stuck to 2 dimensions for our example, we can plot these words on a standard X-Y graph.
  </Description>

  <div className="my-6 p-6 bg-slate-50 dark:bg-slate-800/50 rounded-lg border border-slate-200 dark:border-slate-700">
    <div className="text-center mb-4">
      <span className="text-sm font-medium text-slate-500 dark:text-slate-400">The 2D Meaning Space</span>
    </div>
    
    {/* Simple coordinate visualization */}
    <div className="relative w-full max-w-md mx-auto aspect-square">
      {/* Axes */}
      <div className="absolute inset-0 flex items-center justify-center">
        <div className="w-full h-0.5 bg-slate-300 dark:bg-slate-600"></div>
      </div>
      <div className="absolute inset-0 flex items-center justify-center">
        <div className="h-full w-0.5 bg-slate-300 dark:bg-slate-600"></div>
      </div>
      
      {/* Axis Labels */}
      <div className="absolute w-full top-1/2 -translate-y-full -mt-1 px-2 flex justify-between text-xs font-medium text-slate-500 dark:text-slate-400 pointer-events-none">
        <span>Gender (-)</span>
        <span>Gender (+)</span>
      </div>
      <div className="absolute top-2 left-1/2 transform -translate-x-1/2 text-xs font-medium text-slate-500 dark:text-slate-400">Royalty (+)</div>
      <div className="absolute bottom-2 left-1/2 transform -translate-x-1/2 text-xs font-medium text-slate-500 dark:text-slate-400">Royalty (-)</div>
      
      {/* Points */}
      <div className="absolute top-[15%] right-[20%] flex flex-col items-center">
        <span className="text-2xl">üëë</span>
        <span className="text-xs font-medium text-slate-700 dark:text-slate-300">King</span>
        <span className="text-xs font-mono text-slate-400">[1, 1]</span>
      </div>
      
      <div className="absolute top-[15%] left-[20%] flex flex-col items-center">
        <span className="text-2xl">üë∏</span>
        <span className="text-xs font-medium text-slate-700 dark:text-slate-300">Queen</span>
        <span className="text-xs font-mono text-slate-400">[1, -1]</span>
      </div>
      
      <div className="absolute top-[45%] right-[20%] flex flex-col items-center">
        <span className="text-2xl">üßî</span>
        <span className="text-xs font-medium text-slate-700 dark:text-slate-300">Man</span>
        <span className="text-xs font-mono text-slate-400">[0, 1]</span>
      </div>
      
      <div className="absolute top-[45%] left-[20%] flex flex-col items-center">
        <span className="text-2xl">üë©</span>
        <span className="text-xs font-medium text-slate-700 dark:text-slate-300">Woman</span>
        <span className="text-xs font-mono text-slate-400">[0, -1]</span>
      </div>
      
      <div className="absolute top-[45%] left-1/2 transform -translate-x-1/2 flex flex-col items-center">
        <span className="text-2xl">üçé</span>
        <span className="text-xs font-medium text-slate-700 dark:text-slate-300">Apple</span>
        <span className="text-xs font-mono text-slate-400">[0, 0]</span>
      </div>
    </div>
  </div>

  <Description>
    In this 2D space, every word lands at a specific coordinate. We have turned words into **Geometry**.
  </Description>

  <div className="my-4 space-y-3">
    <div className="flex items-start gap-3 p-3 bg-slate-50 dark:bg-slate-800/40 rounded-lg border border-slate-200 dark:border-slate-700">
      <span className="font-bold text-slate-700 dark:text-slate-300 w-32 shrink-0">Similarity = Closeness</span>
      <span className="text-slate-600 dark:text-slate-400">Words with similar meanings cluster together. King and Queen both sit in the upper region (high Royalty). Man and King share the right side (positive Gender). Meanwhile, Apple sits alone at the origin. It has nothing in common with royalty or gender.</span>
    </div>
    <div className="flex items-start gap-3 p-3 bg-slate-50 dark:bg-slate-800/40 rounded-lg border border-slate-200 dark:border-slate-700">
      <span className="font-bold text-slate-700 dark:text-slate-300 w-32 shrink-0">Region = Topic</span>
      <span className="text-slate-600 dark:text-slate-400">The top half of the graph is the "Royal Region." The right half is the "Male Region." Words naturally organize into neighborhoods of related concepts.</span>
    </div>
  </div>
</Step>


<Step title="4. Algebra on Concepts: The King-Queen Puzzle">
  <Description>
    Because we are now working with geometry, we can do something almost magical. We can perform **arithmetic on meaning itself**.
  </Description>

  <Description>
    This is the most famous demonstration of why Embeddings work. Look at the arrow on the map that points from **King** to **Queen**. That arrow represents "Flipping Gender" while keeping Royalty constant. Now look at the arrow pointing from **Man** to **Woman**.
  </Description>

  <Description>
    In a well-trained model, those two arrows are almost identical. The model has learned that the concept of "Gender" isn't just a label. It is a **specific direction in space**.
  </Description>

  <div className="my-6 p-5 bg-slate-50 dark:bg-slate-800/50 rounded-lg border border-slate-200 dark:border-slate-700">
    <div className="text-center mb-4">
      <span className="text-sm font-medium text-slate-500 dark:text-slate-400">The Famous Word Puzzle</span>
    </div>
    <div className="text-center text-lg font-mono text-slate-800 dark:text-slate-200">
      King - Man + Woman = <span className="text-emerald-600 dark:text-emerald-400 font-bold">?</span>
    </div>
  </div>

  <Description>
    Let's plug in the numbers from Section 2:
  </Description>

  <div className="my-4 p-4 bg-slate-900 dark:bg-slate-950 rounded-lg border border-slate-700">
    <div className="space-y-3 font-mono text-sm">
      <div className="flex items-center gap-3">
        <span className="text-slate-400 w-28">King:</span>
        <span className="text-white">[1.0, 1.0]</span>
      </div>
      <div className="flex items-center gap-3">
        <span className="text-slate-400 w-28">Minus Man:</span>
        <span className="text-red-400">-[0.0, 1.0]</span>
      </div>
      <div className="flex items-center gap-3">
        <span className="text-slate-400 w-28">Plus Woman:</span>
        <span className="text-emerald-400">+[0.0, -1.0]</span>
      </div>
      <div className="pt-3 border-t border-slate-700">
        <div className="text-xs text-slate-500 mb-2">Calculation:</div>
        <div className="space-y-1">
          <div className="text-slate-300">First dimension (Royalty): $1.0 - 0.0 + 0.0 = $ <span className="text-emerald-400 font-bold">1.0</span></div>
          <div className="text-slate-300">Second dimension (Gender): $1.0 - 1.0 + (-1.0) = $ <span className="text-emerald-400 font-bold">-1.0</span></div>
        </div>
      </div>
      <div className="pt-3 border-t border-slate-700 flex items-center gap-3">
        <span className="text-slate-400 w-28">Result:</span>
        <span className="text-emerald-400 font-bold text-lg">[1.0, -1.0]</span>
      </div>
    </div>
  </div>

  <Description>
    Look back at our definitions in Section 2. Which word has the vector `[1.0, -1.0]`?
  </Description>

  <div className="my-4 p-4 bg-emerald-50 dark:bg-emerald-900/20 rounded-lg border border-emerald-200 dark:border-emerald-800">
    <div className="flex items-center justify-center gap-4">
      <span className="text-4xl">üë∏</span>
      <span className="text-2xl font-bold text-emerald-700 dark:text-emerald-400">Queen!</span>
    </div>
  </div>

  <Description>
    By taking the concept of a King, removing the "Man-ness", and adding "Woman-ness", we arrive mechanically at the coordinates for Queen. This proves the model isn't just memorizing definitions. It has structured the language into a **consistent map**.
  </Description>
</Step>


<Step title="5. Implementation: The Embedding Matrix">
  <Description>
    You might be wondering: Who calculates these numbers? Do I have to manually score 50,000 words?
  </Description>

  <Description>
    No. That would be impossible. In Deep Learning, we take the lazy path. We let the model **learn** the coordinates.
  </Description>

  <Description>
    In code, an **Embedding Layer** is simply a massive matrix (a spreadsheet) of floating-point numbers.
  </Description>

  <div className="my-4 grid grid-cols-1 md:grid-cols-2 gap-4">
    <div className="p-4 rounded-lg bg-slate-50 dark:bg-slate-800/50 border border-slate-200 dark:border-slate-700">
      <div className="text-2xl font-semibold text-slate-800 dark:text-slate-200 mb-1">50,000</div>
      <div className="text-sm text-slate-600 dark:text-slate-400">Rows</div>
      <div className="text-xs text-slate-500 mt-2">One for every token ID</div>
    </div>
    <div className="p-4 rounded-lg bg-slate-50 dark:bg-slate-800/50 border border-slate-200 dark:border-slate-700">
      <div className="text-2xl font-semibold text-slate-800 dark:text-slate-200 mb-1">4,096</div>
      <div className="text-sm text-slate-600 dark:text-slate-400">Columns</div>
      <div className="text-xs text-slate-500 mt-2">The number of dimensions</div>
    </div>
  </div>

  <h4 className="text-lg font-semibold text-slate-800 dark:text-slate-200 mt-6 mb-3">The Training Process</h4>

  <Description>
    When we initialize the model, we fill this matrix with random noise. "King" might start at `[0.5, -0.2]`, right next to "Sandwich." The map is nonsense.
  </Description>

  <Description>
    But then we start **Training**. We show the model billions of sentences.
  </Description>

  <div className="my-4 relative">
    <div className="absolute left-6 top-0 bottom-0 w-0.5 bg-slate-200 dark:bg-slate-700" />
    
    <div className="space-y-4">
      <div className="relative flex gap-4">
        <div className="w-12 h-12 rounded-full bg-slate-100 dark:bg-slate-800 border-2 border-slate-300 dark:border-slate-600 flex items-center justify-center text-slate-700 dark:text-slate-300 font-bold z-0">1</div>
        <div className="flex-1 pt-2">
          <div className="font-semibold text-slate-800 dark:text-slate-200">Model sees:</div>
          <div className="font-mono text-sm text-slate-600 dark:text-slate-400 mt-1">"The King sat on the..."</div>
        </div>
      </div>

      <div className="relative flex gap-4">
        <div className="w-12 h-12 rounded-full bg-slate-100 dark:bg-slate-800 border-2 border-slate-300 dark:border-slate-600 flex items-center justify-center text-slate-700 dark:text-slate-300 font-bold z-0">2</div>
        <div className="flex-1 pt-2">
          <div className="font-semibold text-slate-800 dark:text-slate-200">It guesses:</div>
          <div className="font-mono text-sm text-slate-600 dark:text-slate-400 mt-1">A random word</div>
        </div>
      </div>

      <div className="relative flex gap-4">
        <div className="w-12 h-12 rounded-full bg-slate-100 dark:bg-slate-800 border-2 border-slate-300 dark:border-slate-600 flex items-center justify-center text-slate-700 dark:text-slate-300 font-bold z-0">3</div>
        <div className="flex-1 pt-2">
          <div className="font-semibold text-slate-800 dark:text-slate-200">We tell it:</div>
          <div className="font-mono text-sm text-slate-600 dark:text-slate-400 mt-1">The correct answer is "Throne"</div>
        </div>
      </div>

      <div className="relative flex gap-4">
        <div className="w-12 h-12 rounded-full bg-emerald-100 dark:bg-emerald-900/40 border-2 border-emerald-400 dark:border-emerald-600 flex items-center justify-center text-emerald-700 dark:text-emerald-300 font-bold z-0">4</div>
        <div className="flex-1 pt-2">
          <div className="font-semibold text-slate-800 dark:text-slate-200">Backpropagation sends a signal:</div>
          <div className="text-sm text-slate-600 dark:text-slate-400 mt-1 italic">"Move the coordinates of 'King' slightly closer to 'Throne' and further from 'Sandwich'."</div>
        </div>
      </div>
    </div>
  </div>

  <Description>
    Over time, this "nudging" process organizes the random noise into the structured Library of Meaning we visualized above.
  </Description>
</Step>


<Step title="6. The Missing Piece: Word Order">
  <Description>
    We have solved the meaning problem. We can translate "King" into a rich vector that captures its essence.
  </Description>

  <Description>
    But by moving to vectors, we accidentally broke something important: **Sequence**.
  </Description>

  <Description>
    Here's the issue. Traditional language models (like RNNs) read words one by one, left to right, so order is built in. But this sequential approach is painfully slow. You cannot process word #5 until you have finished words #1 through #4. This makes training on billions of sentences take forever.
  </Description>

  <Description>
    Modern architectures solve this by processing all words **in parallel**, reading the entire sentence at once. This is massively faster and more scalable. But it creates a new problem: if you hand the model all words simultaneously, how does it know which came first?
  </Description>

  <Description>
    Consider the sentence "The man bit the dog." If we just hand over a bag of vectors:
  </Description>

  <div className="my-4 p-4 bg-slate-900 dark:bg-slate-950 rounded-lg border border-slate-700">
    <div className="font-mono text-sm text-center text-slate-300">
      {`{Vector(The), Vector(man), Vector(bit), Vector(the), Vector(dog)}`}
    </div>
  </div>

  <ThinkingProcess 
    title="The Order Problem"
    hint={
      <div className="text-sm text-slate-600 dark:text-slate-400">
        What happens if you rearrange these same vectors to represent "The dog bit the man"? What information is lost?
      </div>
    }
  >
    <div className="space-y-4">
      <Description>
        If you rearrange the words to "The dog bit the man," the bag contains the **exact same vectors**. The model knows the participants (man, dog) and the action (bite), but it has completely lost the information about **who did what to whom**.
      </Description>
      <Description>
        We need a way to stamp each word with its position in the sentence. That's what we'll solve next.
      </Description>
    </div>
  </ThinkingProcess>
</Step>


<Step title="7. The Fix: Positional Encodings">
  <Description>
    The solution is elegant: we create a second set of vectors that encode **position** rather than meaning.
  </Description>

  <Description>
    Just as we have a vector that captures the meaning of "Apple", we create vectors that represent "Position 0", "Position 1", "Position 2", and so on.
  </Description>

  <div className="my-4 grid grid-cols-1 md:grid-cols-2 gap-4">
    <div className="p-4 bg-blue-50 dark:bg-blue-900/20 rounded-lg border border-blue-200 dark:border-blue-800">
      <div className="flex items-center gap-2 mb-2">
        <div className="w-8 h-8 rounded-full bg-blue-100 dark:bg-blue-900/50 flex items-center justify-center text-blue-600 dark:text-blue-400 text-lg">üìù</div>
        <span className="font-semibold text-blue-800 dark:text-blue-300">Token Vector</span>
      </div>
      <div className="text-sm text-blue-700 dark:text-blue-300">
        Represents <strong>Content</strong>
      </div>
      <div className="text-xs text-blue-600 dark:text-blue-400 mt-1">
        What is this word?
      </div>
    </div>

    <div className="p-4 bg-amber-50 dark:bg-amber-900/20 rounded-lg border border-amber-200 dark:border-amber-800">
      <div className="flex items-center gap-2 mb-2">
        <div className="w-8 h-8 rounded-full bg-amber-100 dark:bg-amber-900/50 flex items-center justify-center text-amber-600 dark:text-amber-400 text-lg">üìç</div>
        <span className="font-semibold text-amber-800 dark:text-amber-300">Position Vector</span>
      </div>
      <div className="text-sm text-amber-700 dark:text-amber-300">
        Represents <strong>Location</strong>
      </div>
      <div className="text-xs text-amber-600 dark:text-amber-400 mt-1">
        Where does it appear in the sentence?
      </div>
    </div>
  </div>

  <h4 className="text-lg font-semibold text-slate-800 dark:text-slate-200 mt-6 mb-3">Combining Them: Simple Addition</h4>

  <Description>
    To create the final input, we take the Token Vector and simply **add** the Position Vector to it, element by element.
  </Description>

  <div className="my-4 p-4 bg-slate-50 dark:bg-slate-800/50 rounded-lg border border-slate-200 dark:border-slate-700">
    <div className="text-center font-mono text-lg text-slate-800 dark:text-slate-200">
      $FinalInput = TokenVector + PositionVector$
    </div>
  </div>

  <h4 className="text-lg font-semibold text-slate-800 dark:text-slate-200 mt-6 mb-3">Wait, Why Add? Won't That Mix Everything Up?</h4>

  <Description>
    This is a common point of confusion. If we just add the numbers together, won't we lose the separate pieces of information?
  </Description>

  <Description>
    Think of it like mixing **Color** and **Brightness** in a photograph.
  </Description>

  <div className="my-4 space-y-3">
    <div className="flex items-center gap-3 p-3 bg-red-50 dark:bg-red-900/20 rounded-lg border border-red-200 dark:border-red-800">
      <span className="font-bold text-red-700 dark:text-red-400 w-36 shrink-0">Token (Color):</span>
      <span className="text-slate-700 dark:text-slate-300">"Apple" is <span className="font-semibold text-red-600 dark:text-red-400">Red</span></span>
    </div>
    <div className="flex items-center gap-3 p-3 bg-slate-100 dark:bg-slate-800/60 rounded-lg border border-slate-200 dark:border-slate-700">
      <span className="font-bold text-slate-700 dark:text-slate-400 w-36 shrink-0">Position (Brightness):</span>
      <span className="text-slate-700 dark:text-slate-300">"Position 0" is <span className="font-semibold">Dim</span>. "Position 5" is <span className="font-semibold">Bright</span>.</span>
    </div>
  </div>

  <Description>
    When we add them, we get a "Dim Red" vector. Your eyes can still perceive both the color and the brightness as separate qualities. They do not get "lost."
  </Description>

  <Description>
    Neural networks work the same way. With enough training, the model learns to "un-mix" the combined signal. It recognizes "Red" and thinks *fruit*. It recognizes "Dim" and thinks *early in the sentence*.
  </Description>

  <Callout type="tip" title="Why Not Concatenate Instead?">
    We could glue the vectors end-to-end (concatenation), but that would double the vector size. Addition keeps dimensions small and efficient, which matters when you're processing millions of tokens. The model is powerful enough to separate the signals.
  </Callout>
</Step>


<Step title="8. Summary">
  <Callout type="success" title="What We Learned">
    * **Raw Token IDs** cannot be used directly because the model would treat ID 500 as "5√ó more" than ID 100, which is meaningless
    * **Embeddings** are vectors (lists of numbers) that encode meaning. Similar words cluster together in vector space
    * The **Embedding Matrix** is learned during training: the model gradually nudges coordinates based on context
    * **Vector arithmetic** works on concepts: King ‚àí Man + Woman ‚âà Queen
    * **Parallel processing** is fast but loses word order, so we need a fix
    * **Positional Encodings** restore sequence information by adding position vectors to token vectors
    * The **final input** combines both: *what* the word means + *where* it appears
  </Callout>

  <Description>
    We now have a rich, meaningful representation of text that captures both **content** and **position**. This combined vector is what flows into the core of modern language models: the **Attention Mechanism**.
  </Description>

  <Description>
    In the next chapter, we will see how Attention lets words "talk" to each other, allowing "it" to figure out what "it" refers to, and letting the model build understanding of the full sentence.
  </Description>
</Step>
