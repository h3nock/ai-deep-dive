---
title: Embeddings & Lookup Tables
step: 1
description: Implementing the continuous vector space representation of tokens.
---

<SplitLayout>
  <Step>
    <Description>
      ## The Continuous Space

      Neural networks cannot understand raw text. We must map discrete tokens (integers) to continuous vectors (floats).

      ### The Concept
      An embedding layer is essentially a lookup table. Each row in the matrix corresponds to a token in our vocabulary. When we pass a token ID, we retrieve the corresponding row vector.

      ### The Math
      $$ E \in \mathbb{R}^{V \times d} $$
      Where $V$ is vocabulary size and $d$ is the embedding dimension.

      ### Challenge
      Implement a class `Embedding` that initializes a learnable matrix of shape `(vocab_size, d_model)` and defines a `forward` pass that retrieves vectors for a batch of indices.
    </Description>
  </Step>
</SplitLayout>
