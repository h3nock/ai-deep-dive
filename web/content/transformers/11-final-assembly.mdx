---
title: "Final Assembly: Code Translator"
description: "Building a Sequence-to-Sequence model to translate code."
step: 11
challenge: "Build the full Encoder-Decoder Transformer."
---

# Final Assembly: Code Translator

We are building a **Seq2Seq** model to translate code (e.g., `print("hello")` -> `console.log("hello")`).

## The Architecture

1.  **Encoder**:
    *   Takes source tokens (Python).
    *   Passes them through $N$ `EncoderBlock`s.
    *   Outputs a "Memory" matrix (understanding of the code).

2.  **Decoder**:
    *   Takes target tokens (JavaScript so far).
    *   Passes them through $N$ `DecoderBlock`s.
    *   Uses **Cross-Attention** to look at the Encoder's "Memory".
    *   Predicts the next JavaScript token.

## The Flow
```
Source (Python) -> [Encoder] -> Memory
                                   |
Target (JS)     -> [Decoder] <-----|
                                   |
                                 Logits -> Next Token
```

## Your Task
Assemble the full `Transformer` class and write a script to translate simple code snippets!
